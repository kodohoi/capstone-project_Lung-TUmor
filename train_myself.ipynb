{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e549220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torchio as tio\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "logging.getLogger().handlers.clear()\n",
    "\n",
    "from unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663e470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_img_to_label_path(path):\n",
    "    parts = list(path.parts)\n",
    "    parts[parts.index(\"imagesTr\")] = \"labelsTr\"\n",
    "    return Path(*parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"./Task06_Lung/imagesTr/\")\n",
    "subjects_paths = list(path.glob(\"Lung*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ee9bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = []\n",
    "\n",
    "for subject_path in subjects_paths:\n",
    "    label_path = change_img_to_label_path(subject_path)\n",
    "    subject = tio.Subject(CT = tio.ScalarImage(subject_path),\n",
    "                          Label = tio.LabelMap(label_path))\n",
    "    subjects.append(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93255e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects:\n",
    "    assert subject[\"CT\"].orientation == (\"L\", \"A\", \"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ea11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects[0][\"Label\"][\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = tio.Compose([\n",
    "    tio.ToCanonical(),\n",
    "    tio.CropOrPad((500, 500, 300)),\n",
    "    tio.RescaleIntensity((-1,1))\n",
    "])\n",
    "\n",
    "augmentation = tio.RandomAffine(scales=(0.9, 1.1), degrees=(-10, 10))\n",
    "\n",
    "train_transformation = tio.Compose([preprocess, augmentation])\n",
    "val_transformation = preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f182d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tio.SubjectsDataset(subjects[:53], transform=train_transformation)\n",
    "val_dataset = tio.SubjectsDataset(subjects[53:], transform=val_transformation)\n",
    "\n",
    "sampler = tio.data.LabelSampler(patch_size=96, label_name=\"Label\", label_probabilities={0:0.00001, 1:0.99999})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e50d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_patches_queue = tio.Queue(\n",
    "        train_dataset,\n",
    "        max_length=40,\n",
    "        samples_per_volume=5,\n",
    "        sampler=sampler,\n",
    "        num_workers=8)\n",
    "\n",
    "val_patches_queue = tio.Queue(\n",
    "        val_dataset,\n",
    "        max_length=40,\n",
    "        samples_per_volume=5,\n",
    "        sampler=sampler,\n",
    "        num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "train_loader = torch.utils.data.DataLoader(train_patches_queue, batch_size=batch_size, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_patches_queue, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4e7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Helper Class which implements the intermediate Convolutions\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.step = torch.nn.Sequential(torch.nn.Conv3d(in_channels, out_channels, 3, padding=1),\n",
    "                                        torch.nn.ReLU(),\n",
    "                                        torch.nn.Conv3d(out_channels, out_channels, 3, padding=1),\n",
    "                                        torch.nn.ReLU())\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.step(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6241791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements a UNet for the Segmentation\n",
    "    We use 3 down- and 3 UpConvolutions and two Convolutions in each step\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Sets up the U-Net Structure\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        \n",
    "        ############# DOWN #####################\n",
    "        self.layer1 = DoubleConv(1, 32)\n",
    "        self.layer2 = DoubleConv(32, 64)\n",
    "        self.layer3 = DoubleConv(64, 128)\n",
    "        self.layer4 = DoubleConv(128, 256)\n",
    "\n",
    "        #########################################\n",
    "\n",
    "        ############## UP #######################\n",
    "        self.layer5 = DoubleConv(256 + 128, 128)\n",
    "        self.layer6 = DoubleConv(128+64, 64)\n",
    "        self.layer7 = DoubleConv(64+32, 32)\n",
    "        self.layer8 = torch.nn.Conv3d(32, 1, 1)  \n",
    "        #########################################\n",
    "\n",
    "        self.maxpool = torch.nn.MaxPool3d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ####### DownConv 1#########\n",
    "        x1 = self.layer1(x)\n",
    "        x1m = self.maxpool(x1)\n",
    "        ###########################\n",
    "        \n",
    "        ####### DownConv 2#########        \n",
    "        x2 = self.layer2(x1m)\n",
    "        x2m = self.maxpool(x2)\n",
    "        ###########################\n",
    "\n",
    "        ####### DownConv 3#########        \n",
    "        x3 = self.layer3(x2m)\n",
    "        x3m = self.maxpool(x3)\n",
    "        ###########################\n",
    "        \n",
    "        ##### Intermediate Layer ## \n",
    "        x4 = self.layer4(x3m)\n",
    "        ###########################\n",
    "\n",
    "        ####### UpCONV 1#########        \n",
    "        x5 = torch.nn.Upsample(scale_factor=2, mode=\"trilinear\")(x4)  # Upsample with a factor of 2\n",
    "        x5 = torch.cat([x5, x3], dim=1)  # Skip-Connection\n",
    "        x5 = self.layer5(x5)\n",
    "        ###########################\n",
    "\n",
    "        ####### UpCONV 2#########        \n",
    "        x6 = torch.nn.Upsample(scale_factor=2, mode=\"trilinear\")(x5)        \n",
    "        x6 = torch.cat([x6, x2], dim=1)  # Skip-Connection    \n",
    "        x6 = self.layer6(x6)\n",
    "        ###########################\n",
    "        \n",
    "        ####### UpCONV 3#########        \n",
    "        x7 = torch.nn.Upsample(scale_factor=2, mode=\"trilinear\")(x6)\n",
    "        x7 = torch.cat([x7, x1], dim=1)       \n",
    "        x7 = self.layer7(x7)\n",
    "        ###########################\n",
    "        \n",
    "        ####### Predicted segmentation#########        \n",
    "        ret = self.layer8(x7)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc90002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, mask, smooth=1):\n",
    "        #flatten label and prediction tensors\n",
    "        pred = pred.view(-1)\n",
    "        mask = mask.view(-1)\n",
    "        \n",
    "        intersection = (pred * mask).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(pred.sum() + mask.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b95c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmenter(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = UNet()\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr = 1e-6)\n",
    "        self.loss_fn = DiceLoss()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        return self.model(data)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img = batch[\"CT\"][\"data\"]\n",
    "        label = batch[\"Label\"][\"data\"]\n",
    "        label = label.long()\n",
    "        \n",
    "        pred = self(img)\n",
    "        \n",
    "        loss = self.loss_fn(pred, label)\n",
    "        \n",
    "        self.log(\"Train Dice\", loss)\n",
    "        if batch_idx % 25 == 0:\n",
    "            self.log_images(img.cpu(), pred.cpu(), label.cpu(), \"Train\")\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img = batch[\"CT\"][\"data\"]\n",
    "        label = batch[\"Label\"][\"data\"]\n",
    "        label = label.long()\n",
    "        \n",
    "        pred = self(img)\n",
    "        \n",
    "        loss = self.loss_fn(pred, label)\n",
    "        \n",
    "        self.log(\"Val Dice\", loss)\n",
    "        self.log_images(img.cpu(), pred.cpu(), label.cpu(), \"Val\")\n",
    "        return loss\n",
    "    \n",
    "    def log_images(self, img, pred, label, name):\n",
    "        pred = pred >0.5\n",
    "        axial_slice = 50\n",
    "        fig, axis = plt.subplots(1,2)\n",
    "        axis[0].imshow(img[0][0][:,:,axial_slice], cmap=\"bone\")\n",
    "        label_ = np.ma.masked_where(label[0][0][:,:,axial_slice]==0, label[0][0][:,:,axial_slice])\n",
    "        axis[0].imshow(label_, alpha=0.5)\n",
    "        \n",
    "        axis[1].imshow(img[0][0][:,:,axial_slice], cmap=\"bone\")\n",
    "        label_ = np.ma.masked_where(label[0][0][:,:,axial_slice]==0, label[0][0][:,:,axial_slice])\n",
    "        axis[1].imshow(label_, alpha=0.5)\n",
    "        \n",
    "        self.logger.experiment.add_figure(name, fig, self.global_step)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return [self.optimizer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a3b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Segmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f766496",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"Val Dice\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"Val Dice\",\n",
    "    mode=\"min\",\n",
    "    patience=20,\n",
    "    min_delta=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9b05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus=1\n",
    "trainer = pl.Trainer(gpus=gpus, logger=TensorBoardLogger(save_dir=\"./logs\"), log_every_n_steps=1,\n",
    "                     callbacks=[checkpoint_callback, early_stop], max_epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a2f3c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae182a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from celluloid import Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b042f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Segmenter.load_from_checkpoint(r\"./logs/lightning_logs/version_9/checkpoints/epoch=10-step=374.ckpt\")\n",
    "model2 = model2.eval()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model2.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d4704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 2\n",
    "mask = val_dataset[IDX][\"Label\"][\"data\"]\n",
    "imgs = val_dataset[IDX][\"CT\"][\"data\"]\n",
    "\n",
    "# GridSampler\n",
    "grid_sampler = tio.inference.GridSampler(val_dataset[IDX], 96, (8, 8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9668fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregator = tio.inference.GridAggregator(grid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d93d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_loader = torch.utils.data.DataLoader(grid_sampler, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd0f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for patches_batch in patch_loader:\n",
    "        input_tensor = patches_batch['CT'][\"data\"].to(device)  # Get batch of patches\n",
    "        locations = patches_batch[tio.LOCATION]  # Get locations of patches\n",
    "        pred = model2(input_tensor)  # Compute prediction\n",
    "        aggregator.add_batch(pred, locations)  # Combine predictions to volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e77aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = aggregator.get_output_tensor()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffbe3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "camera = Camera(fig)  # create the camera object from celluloid\n",
    "pred = output_tensor.argmax(0)\n",
    "\n",
    "for i in range(0, output_tensor.shape[3], 2):  # axial view\n",
    "    plt.imshow(imgs[0,:,:,i], cmap=\"bone\")\n",
    "    #mask_ = np.ma.masked_where(pred[:,:,i]==0, pred[:,:,i])\n",
    "    label_mask = np.ma.masked_where(mask[0,:,:,i]==0, mask[0,:,:,i])\n",
    "    plt.imshow(pred[:,:,i], alpha=0.5, cmap=\"autumn\")\n",
    "    #plt.imshow(label_mask, alpha=0.5, cmap=\"jet\")  # Uncomment if you want to see the label\n",
    "\n",
    "    # plt.axis(\"off\")\n",
    "    camera.snap()  # Store the current slice\n",
    "animation = camera.animate()  # create the animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f81626",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(animation.to_html5_video()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cef448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
